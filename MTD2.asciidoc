= {nbsp}{nbsp}{nbsp}{nbsp}{nbsp}{nbsp}{nbsp}{nbsp}{nbsp}Vilniaus Gedimino technikos universitetas

[.text-center]
== Elektronikos fakultetas

=== Kompiuterijos ir ryšių technologijų katedra

{nbsp}

{nbsp}

{nbsp}

{nbsp}

=== Magistro tiriamasis darbas 2
Modulis ELKRM17203

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

[.text-right]
**Atliko:** TETfm-20 grupės magistrantas +
                       Saulius Krasuckas +
**Tikrino:** doc. dr. Darius Guršnys

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

VILNIUS, 2021

<<<
---

[.text-left]
=== Turinys

{nbsp}

{nbsp}

==== 1. DCN tipai
==== 2. Ką išsprendžia MPTCP ir kokie jo trūkumai?
==== 3. Energonašumas
==== 4. Santykis su _Legacy_ aplikacijomis
==== 5. Papildomi aspektai
==== 6. Galimi MPTCP protokolo saugumo klausimai
==== 7. Galima fizinė 10 Gbps įranga bandymams

<<<
=== 1. DCN tipai
[.text-left]

* Kokie yra DCN (Data Center Networks) tipai?
** **Telco Distributed DC with Transport Protocol Enhancement for 5G Mobile Networks**,  +
   A Survey, December 2017  +
   https://www.diva-portal.org/smash/get/diva2:1164941/FULLTEXT01.pdf#page=10
+
--
____
> 2 Overview of Data Center Architectures +
2.1 Data Center Network Topologies +
3 Data Center Networking +
3.1 Data Center Network +
3.2 Data Center Networking +
____
--
+
image::https://user-images.githubusercontent.com/74717106/123442861-ffbd0b00-d5dd-11eb-8824-a657c3d0ad83.png[]

* Kurį DCN tipą (ar kelis) tirsime / emuliuosime?
** Tree-based
*** Basic Tree
*** Fat Tree
*** Clos Tree
*** Spine-Leaf
** Recursive
*** DCell
*** BCube
*** MDCube
** Kiti, labiau aktualūs Telco-NG architektūrai (Ericsson)
** Ieškau balanso tarp realistiškumo ir prieinamumo:
*** fiziniam modeliui
*** modeliui su virtualiomis mašinomis

=== 2. Ką išsprendžia MPTCP ir kokie jo trūkumai?
[.text-left]

Trūkumus labiausiai ir taikausi tirti:

[.text-left]
* Pagal **Tuning high flow concurrency for MPTCP in data center networks**, 24 February 2020 +
   https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-020-00160-3 +
   +
Išsprendžia:
+
--
____
> As the de facto load balancing scheme in data center, Equal Cost Multipath (ECMP) [3] randomly sends each flow to one of the parallel paths by hash function. Though ECMP is very simple, it suffers from well-known performance problems such as hash collisions and low link utilization. Random Packet Spraying (RPS) [4] is a packet-level load balancing scheme that sprays each packet to a random path to obtain high link utilization, while also leading to packet reordering and throughput loss. Compared with the flow-level and packet-level load balancing schemes, MultiPath TCP (MPTCP) uses parallel subflows as the rerouting granularity to achieve better tradeoff in minimizing packet reordering and increasing link utilization [5].
____
--
image::https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs13677-020-00160-3/MediaObjects/13677_2020_160_Fig1_HTML.png?as=webp[]
+
Trūkumai: 
+
--
____
> Unfortunately [...] the number of subflows has significant impact on MPTCP performance. On the one hand, if the number of subflows is small, the network resources of multiple paths are wasted, resulting in **suboptimal flow completion time** and even **hot spots in congested paths**. On the other hand, if the number of subflows is large, the congestion window of each subflow becomes very small, easily **leading to timeout** (i.e., full window loss) and **high tail latency** under heavy congestion [6–10].  
____
--

* Pagal **MULTIPATH TCP**, 10 DEC 2016  +
   https://network-insight.net/2016/12/multipath-tcp/  +
   +
Išsprendžia:
+
--
____
> Next generation leaf and spine data centre networks are built with Equal-Cost Multipath (ECMP). [...] For one endpoint to communicate to another, a TCP flow is placed on a single link, not spread over multiple links. As a result, single-path TCP collisions may occur, reducing the throughput available to that flow. This is commonly seen for large flows and not small mice flows.  +
>  +
> In a data centre when a server starts a TCP connection it gets placed on a path and stays there. With MPTCP instead of using a single path per connection you could use many subflows per connection. If some of those subflows get congested, you just don’t send over that particular subflow improving traffic fairness and bandwidth optimisations.  +
>  +
> The default behaviour of spreading traffic through a LAG or ECMP next hops is based on the hash-based distribution of packets. An array of buckets is created, and each outbound link is assigned to one or more buckets. Fields are taken from the outgoing packet header such as source-destination IP address / MAC address and hashed based on this endpoint identification. A bucket is selected by the hash and the packet is queued to the interface that is assigned that bucket.  +
>  +
> The issue here is that the load balancing algorithm does not take into account interface congestions or packet drops. With all mice flows this is fine but once you mix mice and elephant flows together your performance will suffer. An algorithm is needed to identify congested links and then reshuffle the traffic. A good use for MPTCP is when you have a mix of mice and elephant flows.
____
--
+
Trūkumai:
+
--
____
> Generally, MPTCP **does not improve performance** for environments **with only mice flows**.  
> 
> With small files say 50KB MPTCP offers the same performance as regular TCP. As the file size increases MPTCP usually has the same results as link bonding. The benefits of MPTCP come to play when files are very big (300 KB ). At this level,  MPTCP outperforms link bonding as the congestion control can efficiently balance the load better over the links.  
____
--
+

* Pagal:  +
   https://slideplayer.com/slide/17007643/[**AMP: An Adaptive Multipath TCP for Data Center Networks**, IFIP Networking 2019]  +
   https://arxiv.org/pdf/1707.00322.pdf[**AMP: A Better Multipath TCP for Data Center Networks**, 17 Mar 2019]  +
   https://github.com/mkheirkhah/amp[**Adaptive MultiPath TCP (AMP) implementation in ns-3**]  +
    +
   Išsprendžia:
+
--
____
> ECN-based multipath schemes seem to provide a good balance between **the latency-throughput trade-off**  +
____
--
+
Trūkumai:
+
--
____
> **Problems with ECN-capable variant of MPTCP**  +
> * TCP Incast  +
>   Well-studied topic for TCP (not really for MPTCP)  +
>   Each subflow maintains a separate congestion window  +
>   More subflows, more chance of experiencing a retransmission timeout during an incast episode  +
>  +
> * Last Hop Unfairness (LHU)  +
>   We are reporting it for the first time

image::https://user-images.githubusercontent.com/74717106/123442566-abb22680-d5dd-11eb-81ac-90a63745836d.png[]

> **Problem 1: Incast**  +
>  +
> * MPTCP and its ECN-capable variants are not robust against the Incast problem… +
>  +
>  -- More subflows --> More packets --> Buffer overflow --> Higher chance of RTO in each subflow especially when the congestion window is small  +
>     +
>     Why is that? The problem is very simple, the more subflows is used, the more packets is generated.  +
>     +
>     As a result the switch buffer can easily overflow.  +
>     +
>     Which implies higher chance of RTO in each subflow especially when the congestion window is small (less than 10 packets).

image::https://user-images.githubusercontent.com/74717106/123442376-7d344b80-d5dd-11eb-96f8-8b7cc66ddbe3.png[]

> **Problem 2: Last Hop Unfairness**  +
>  +
> Let’s assume:  +
> Propagation delay is zero  +
> Marking threshold (K) at switches sets to 4 packets (K=4)  +
> Minimum congestion window size sets to one packet (cwndmin=1)  +
>  +
> Normal situation  +
> Two single-path flows share the link fairly. Each flow generating two packets per RTT on average  +
>  +
> To explore this problem let’s assume:  +
> PBI: A new arriving… because number of competing flows with minimum cwnd is higher than marking threshold K  +
> LHU: now we can see not only MPTCP cause serious buffer inflation but also it is seriously unfair to competing flows  +
>  +
> The LHU leads to severe unfairness and significantly escalates the likelihood of persistent buffer inflation

> **Summary Existing multipath congestion control schemes fail to handle:**
> 
> * The TCP incast problem that causes **temporal switch buffer overflow** due to synchronized traffic arrival
> * The last hop unfairness that causes **persistent buffer inflation** and serious **unfairness**
____
--
+

* Kaip DC pritaikomas / kiek sklandus / **ar vertas matavimo** srauto Handover-is:
** **Understanding Multipath TCP: High availability for endpoints and the networking highway of the future**, February 9, 2021  +
   https://www.redhat.com/en/blog/understanding-multipath-tcp-networking-highway-future
+
--
____
> just like a highway clover-leaf interchange where traffic from one highway can merge onto the other with ease, MPTCP allows mobile hosts to **hand over traffic** from Wi-Fi to cellular, **without disrupting the application**.
____
--
+

* Kiek verta tiesiogiai tirti _Network Collision_ pasikeitimus įjungus MPTCP?  +
+
--
____
> MPTCP also dramatically **reduces the number of network collisions**, which is why you never achieve the full speed of any connection.
____
--


<<<
=== 3. Energonašumas:
[.text-left]

* `eMTCP` – energy-aware MPTCP  +
    **A Traffic Burstiness-based Offload Scheme for Energy Efficiency Deliveries in Heterogeneous Wireless Networks**  +
    https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.702.3596&rep=rep1&type=pdf
* Kurį kriterijų renkamės: angl. _**Power** efficiency_ vs _**Energy** efficiency_ ?  +
    https://itpeernetwork.intel.com/power-and-energy-efficiency-double-your-benefit/  +
+
--
____
> Power efficiency is about doing more within a fixed capability  +
> Energy Efficiency is about “making every kWh count”
____
--

=== 4. Santykis su _Legacy_ aplikacijomis:
[.text-left]

* Ar DC tyrimams praverstų **MPTCP Proxy** naudojimas?  +
  Ypač kai OS nepalaiko MPTCP (pvz. Windows Server + SQL)
** **Multipath TCP Proxy: Unshackling Network Nodes from Today’s End-to-End Connection Principle**,  13 Jan 2017  +
   https://hal.inria.fr/hal-01434867/document
+
--
____
> image::https://user-images.githubusercontent.com/74717106/123441981-1e6ed200-d5dd-11eb-8a93-91342354d422.png[]
> Fig. 1. Creation of the split TCP-MPTCP connection, after insertion of the MPTCP Proxy in between the communication ends.

____
--
+

** https://spyff.github.io/mptcp/2017/08/27/transparent-mptcp-proxy/  +
   **Multipath Wi-Fi bridging with transparent MPTCP proxy on LEDE**, 2017-08-27
+
--
____
> **2. Assemble the physical test environment**
> 
> image::https://raw.githubusercontent.com/spyff/draw.io/master/GSoC2017_final_topology.jpg[]
> 
> For the tests, I use the following hardware:  +
> +
> Netgear R7000 router  +
> Netgear R7800 router  +
> 2 Ubiquiti Loco M5 Wi-Fi bridges  +
> 2 Ubiquiti M5 Wi-Fi bridges  +
> Lots of small UTP cables  +
> A PC and a Laptop (or in some cases a RaspberryPi and a Laptop for the portable setup)  +
____
--
+

* Linux STAP (angl. _System Tap_) įrankio naudojimas `IPPROTO_MPTCP` įjungimui `socket()` kvietimo metu.

<<<
=== 5. Papildomi aspektai
[.text-left]

* Pritaikomumo CDNams tyrimo galimybės įvertinimas:  
** **Network Architecture (R02) | IP Multipath – Path Selection&CC**  +
    Jon Crowcroft  +
    https://www.cl.cam.ac.uk/teaching/1213/R02/slides/r02-mpath.ppt#page=2  +
+
--
____
> * IP or Application Layer
>   * CDN, especially P2P (Torrent or Storm)
>     already effectively multipath at App
>   * Current IP routing mainly only corner cases
____
--

* WireGuard tunelio panaudojimas MPTCP srauto perdavimui per tuos DC _Middlebox_ mazgus, kurie blokuoja MPTCP žymes/laukus, bet praleidžia UDP.

* Ar DC reikalingas specifinis kelių valdiklio (angl. _**Path manager**_) konfigūravimas?
* Ar DC reikalingas dinaminis _Routing Table_ valdymas?  
** **Multipath TCP with real Smartphone applications**, 6 Jan 2015  +
   https://dial.uclouvain.be/memoire/ucl/fr/object/thesis%3A366/datastream/PDF_01/view  +
+
--
____
> Simply installing a new Multipath TCP-ready kernel is not enough if you want to use multiple network interfaces at the same time. Indeed, you need to configure routing tables as described on the Multipath TCP’s website [8]
____
--

** The **Multipath TCP in the Linux Kernel** wiki,  +
   Users/Testers > **Configure Routing**:  +
   http://multipath-tcp.org/pmwiki.php/Users/ConfigureRouting
+
--
____
> **Manual configuration**  +
> ...
> 
  mptcp-kernel:~# ip rule show
  0:      from all lookup local
  32764:  from 10.1.2.2 lookup 2
  32765:  from 10.1.1.2 lookup 1
  32766:  from all lookup main
  32767:  from all lookup default
 #
  mptcp-kernel:~# ip route
  10.1.1.0/24 dev eth0  proto kernel  scope link  src 10.1.1.2
  10.1.2.0/24 dev eth1  proto kernel  scope link  src 10.1.2.2
  default via 10.1.1.1 dev eth0
 #
  mptcp-kernel:~# ip route show table 1
  10.1.1.0/24 dev eth0  scope link
  default via 10.1.1.1 dev eth0
 #
  mptcp-kernel:~# ip route show table 2
  10.1.2.0/24 dev eth1  scope link
  default via 10.1.2.1 dev eth1

> **Automatic configuration with "Multihomed-Routing"**  +
> ...  +
> Kristian Evensen <kristian.evensen@gmail.com> developed a set of scripts that integrate well with existing Network Managers to properly configure the multihomed routing. Check it out at:
____
--
+

** https://github.com/kristrev/multihomed-routing  +
**Tools and scripts for configuring multihomed routing on Linux**  +
  +
   Vienas iš naujų įrankų:
*** Veikia su `Network Manager` valdikliu.
*** Ar veikia su nauju `netplan` valdikliu?

* Nors bandymų planas pradedamas nuo OpenWRT grįstos Linux distribucijos **OpenMPTCPRouter**, galiausiai esu numatęs naudoti serverinę distribuciją **RHEL 8.3** arba **8.4**:

** **Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows**, August 19, 2020  +
   https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows
+
--
____
> Multipath TCP (MPTCP) extends traditional TCP to allow reliable end-to-end delivery over multiple simultaneous TCP paths, and is coming as a **tech preview on Red Hat Enterprise Linux 8.3**. This is the first of two articles for users who want to practice with the new MPTCP functionality on a live system. In this first part, we show you how to enable the protocol in the kernel and let client and server applications use the MPTCP sockets. Then, we run diagnostics on the kernel in a sample test network, where endpoints are using a single subflow.
____
--

** Phoronix portalo diskusija:  +
   **Red Hat Bringing Multipath TCP To RHEL 8.3 As A Tech Preview**, 19 August 2020  +
   https://www.phoronix.com/forums/forum/software/distributions/1201614-red-hat-bringing-multipath-tcp-to-rhel-8-3-as-a-tech-preview#post1201689
+
--
____
> Pretty sure RH's interest in the backport is for their customers **large DC solutions**, where **100/200GbE NICs** are the sweet spot (400/800 GbE NICs are still somewhat niche solutions), but higher network performance is required.
____
--
Beveik akivaizdu, jog tyrimams reikalingi **10G** spartos **NIC**.  +
 +

** **Red Hat Enterprise Linux8Configuring and managing networking** gidas:  +
   https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/getting-started-with-multipath-tcp_configuring-and-managing-networking
+
--
____
> **27. Getting started with Multipath TCP**  +
> ...  +
> **27.1. Preparing RHEL to enable MPTCP support**  +
> Few applications natively support MPTCP. Mostly, the connection and stream-oriented sockets request TCP protocol in the socket() call to the operating system. You can enable MPTCP support in RHEL using the sysctl tool for natively MPTCP-supported programs. The MPTCP implementation is also designed to allow usage of MPTCP protocol for applications requesting IPPROTO_TCP call to the kernel.  +
>  +
> This procedure describes how to enable MPTCP support and prepare RHEL for enabling MPTCP system-wide using a SystemTap script.
____
--

<<<
=== 6. Galimi MPTCP protokolo saugumo klausimai
[.text-left]

* **Cross-path data fragmentation**: +
  https://www.redhat.com/en/blog/understanding-multipath-tcp-networking-highway-future
+
--
____
> Multipath routing causes cross-path data fragmentation. From a security perspective that **challenges in-line security solutions** (e.g., firewalls, IDSs, and malware scanners) which only "see" one path's traffic. Without being able to see all paths, these devices may miss activity that they're meant to be monitoring for. These intermediary devices act a bit like an airport body scanner for the passengers wanting to enter the airport gate area. 
____
--

* **Senas ir naujas požiūris į TCP sesijos duomenų išlygiagretinimą**
+
--
____
> So does that make Firewalls useless?  No, of course not. Perimeter and inline security solutions, like Firewalls and Intrusion Detection Systems, are not dead.  They have and always will perform important duties for protecting perimeters.  Perimeters are more numerous and now include an organization's cloud infrastructure. But, security approaches like Zero Trust and the Cloud Security Alliance's **Software Defined Perimeter (SDP)** provide a new approach that applies to the world where end-user devices are everywhere and not restricted to office only use and applications that are also everywhere, ranging from on-premise to private cloud and public cloud.
____
--

* **Security Evaluation of Multipath TCP** +
  https://www.diva-portal.org/smash/get/diva2:934158/FULLTEXT01.pdf
+
--
____
> The new protocol has been carefully crafted to meet the required security goals, but due to its
very nature, it inevitably changes how data is transferred across the networks, drastically affecting
the way information can be accessed and inspected. From this perspective, working on the security
evaluation of MPTCP has important implications regarding ethical concerns. By splitting a logical
flow of data into different subflows with no predictable scheduling pattern, perhaps involving
different ISPs for different subflows, would make it so **much harder to inspect and eavesdrop useful
information regarding the ongoing connections** by acting within the core of the Internet. Despite
this might be seen as a potential benefit for clients aiming at achieving full anonymization in
the network, many **current intrusion mechanisms and similar technologies might fail** under these
new circumstances, perhaps causing even more security threats overall.  +
>  +
> Overall, MPTCP **can drastically change how privacy is handled** within the Internet, while **the
security aspects should remain unchanged, if not improved**, with respect to current TCP. Moreover,
MPTCP would bring a positive impact for the environment due to a better resources exploitation,
if deployed at large scale. Finally, the new protocol would allow to achieve a series of benefits that
could drastically improve user experience for data transferring in the Internet as well as within
data centers, i.e. wherever TCP is currently adopted
____
--

<<<
=== 7. Galima fizinė 10 Gbps įranga bandymams
[.text-left]

1. Cisco **UCS 5108** Cisco Unified Computing System, 6U:
 - 1 vnt.:  +
   8 vnt. Intel Xeon  E7-4870 30M Cache, 2.40 GHz, 6.40 GT/s Intel® QPI 10c/20t + 1024 GiB RAM
 - 4 vnt. B440 M2 blades. Blade Specs:  +
   *  2 x Intel Xeon  E7-4870 30M Cache, 2.40 GHz, 6.40 GT/s Intel® QPI 10c/20t  (2 No - spare)  +
   * 16 x 16 GiB = 256 GiB DDR3-10600R RAM  +
 - 2 vnt. 8-Ports UCS 2208XP 10Gb Fabric Extender
 - 4 vnt. 2500 W PSU
 - 4 vnt. B440 M2 blades

2. Cisco N5K-C5548UP-FA **Nexus 5548 UP** Chassis 32-Port **10Gb Ethernet Switch**
 - 2 vnt.

3. Cisco UCS-FI-6248UP **32-Port 10Gb Fabric Interconnect Switch**
 - 2 vnt.
 
4. Įrangos rinkinio preliminari kaina:
 - 2.650 €
